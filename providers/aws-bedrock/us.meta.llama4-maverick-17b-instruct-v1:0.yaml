model: us.meta.llama4-maverick-17b-instruct-v1:0
costs:
  input_cost_per_token: 2.4e-7
  output_cost_per_token: 9.7e-7
  input_cost_per_token_batches: 1.2e-7
  output_cost_per_token_batches: 4.85e-7
limits:
  max_tokens: 4096
  max_input_tokens: 128000
  max_output_tokens: 4096
features: [function_calling, chat]
mode: chat
original_provider: bedrock_converse
