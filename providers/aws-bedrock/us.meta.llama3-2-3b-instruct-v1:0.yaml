model: us.meta.llama3-2-3b-instruct-v1:0
costs:
  input_cost_per_token: 1.5e-7
  output_cost_per_token: 1.5e-7
limits:
  max_tokens: 4096
  max_input_tokens: 128000
  max_output_tokens: 4096
capabilities: [function_calling, chat]
source: ''
params: []
removeParams: []
requiredParams: []
mode: chat
defaultRegion: ''
deprecation_date: ''
is_deprecated: false
original_provider: bedrock
