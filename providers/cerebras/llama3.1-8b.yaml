model: llama3.1-8b
costs:
  input_cost_per_token: 1.e-7
  output_cost_per_token: 1.e-7
limits:
  max_input_tokens: 128000
  max_output_tokens: 128000
features: [function_calling, chat]
params:
  - key: max_tokens
    maxValue: 32768
mode: chat
original_provider: cerebras
