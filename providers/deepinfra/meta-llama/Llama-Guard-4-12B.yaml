model: meta-llama/Llama-Guard-4-12B
costs:
  input_cost_per_token: 1.8e-7
  output_cost_per_token: 1.8e-7
limits:
  max_tokens: 163840
  max_input_tokens: 163840
  max_output_tokens: 163840
mode: chat
original_provider: deepinfra
