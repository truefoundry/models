model: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
costs:
  input_cost_per_token: 2.e-8
  output_cost_per_token: 3.e-8
limits:
  max_tokens: 131072
  max_input_tokens: 131072
  max_output_tokens: 131072
features: []
params: []
removeParams: []
requiredParams: []
mode: chat
defaultRegion: ''
deprecation_date: ''
is_deprecated: false
original_provider: deepinfra
