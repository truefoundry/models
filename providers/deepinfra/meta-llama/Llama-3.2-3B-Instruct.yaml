model: meta-llama/Llama-3.2-3B-Instruct
costs:
  input_cost_per_token: 2.e-8
  output_cost_per_token: 2.e-8
limits:
  max_tokens: 131072
  max_input_tokens: 131072
  max_output_tokens: 131072
mode: chat
original_provider: deepinfra
