model: gpt-4o-mini
costs:
  input_cost_per_token: 1.5e-7
  output_cost_per_token: 6.e-7
  input_cost_per_token_batches: 7.5e-8
  output_cost_per_token_batches: 3.e-7
  cache_read_input_token_cost: 7.5e-8
limits:
  max_input_tokens: 128000
  max_output_tokens: 16384
features: [function_calling, parallel_function_calling, vision, chat, image]
params:
  - key: max_tokens
    maxValue: 16384
  - key: response_format
    defaultValue: null
    options:
      - value: null
        name: Text
      - value: json_object
        name: JSON Object
        schema:
          type: object
          properties:
            type:
              type: string
              value: json_object
      - value: json_schema
        name: JSON Schema
        schema:
          type: object
          properties:
            type:
              type: string
              value: json_schema
            json_schema:
              type: object
        params:
          key: json_schema
          defaultValue: null
          type: json
          skipValues:
            - null
    skipValues:
      - null
    type: string
mode: chat
original_provider: openai
