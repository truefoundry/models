model: meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
costs:
  input_cost_per_token: 2.7e-7
  output_cost_per_token: 8.5e-7
features: [function_calling, parallel_function_calling]
mode: chat
original_provider: together_ai
