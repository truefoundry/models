model: meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo
costs:
  input_cost_per_token: 0.0000035
  output_cost_per_token: 0.0000035
limits: {}
features: [function_calling, parallel_function_calling]
source: ''
params: []
removeParams: []
requiredParams: []
mode: chat
defaultRegion: ''
deprecation_date: ''
is_deprecated: false
original_provider: together_ai
