model: zai-org/GLM-4.7
costs:
  input_cost_per_token: 4.5e-7
  output_cost_per_token: 0.000002
limits:
  max_tokens: 200000
  max_input_tokens: 200000
  max_output_tokens: 200000
features: [function_calling, parallel_function_calling]
mode: chat
original_provider: together_ai
