model: meta-llama/llama-4-maverick-17b-128e-instruct
costs:
  input_cost_per_token: 2.e-7
  output_cost_per_token: 6.e-7
limits:
  max_tokens: 8192
  max_input_tokens: 131072
  max_output_tokens: 8192
capabilities:
  supports_function_calling: true
  supports_vision: true
  supports_tool_choice: true
  supports_response_schema: true
source: ''
params: []
removeParams: []
requiredParams: []
mode: chat
defaultRegion: ''
deprecation_date: ''
is_deprecated: false
original_provider: groq
