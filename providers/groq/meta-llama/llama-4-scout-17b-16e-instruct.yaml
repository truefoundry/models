model: meta-llama/llama-4-scout-17b-16e-instruct
costs:
  input_cost_per_token: 1.1e-7
  output_cost_per_token: 3.4e-7
limits:
  max_tokens: 8192
  max_input_tokens: 131072
  max_output_tokens: 8192
features: [function_calling, vision]
mode: chat
original_provider: groq
