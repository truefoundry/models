model: Meta-Llama-3.1-405B-Instruct
costs:
  input_cost_per_token: 0.00000533
  output_cost_per_token: 0.000016
limits:
  max_tokens: 4096
  max_input_tokens: 128000
  max_output_tokens: 2048
features: [chat]
mode: chat
original_provider: azure_ai
