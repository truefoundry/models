model: Llama-4-Maverick-17B-128E-Instruct-FP8
costs:
  input_cost_per_token: 0.00000141
  output_cost_per_token: 3.5e-7
limits:
  max_tokens: 4096
  max_input_tokens: 1000000
  max_output_tokens: 16384
capabilities: [function_calling, vision, chat]
source: https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/
params: []
removeParams: []
requiredParams: []
mode: chat
defaultRegion: ''
deprecation_date: ''
is_deprecated: false
original_provider: azure_ai
