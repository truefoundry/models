model: llama-3.1-8b-instruct-maas
costs:
  input_cost_per_token: 0
  output_cost_per_token: 0
limits:
  max_tokens: 2048
  max_input_tokens: 128000
  max_output_tokens: 2048
features: [vision]
mode: chat
original_provider: vertex_ai-llama_models
