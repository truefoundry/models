model: llama-4-maverick-17b-128e-instruct-maas
costs:
  input_cost_per_token: 3.5e-7
  output_cost_per_token: 0.00000115
limits:
  max_tokens: 1000000
  max_input_tokens: 1000000
  max_output_tokens: 1000000
features: [function_calling]
mode: chat
original_provider: vertex_ai-llama_models
