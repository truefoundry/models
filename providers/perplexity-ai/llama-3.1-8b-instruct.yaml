model: llama-3.1-8b-instruct
costs:
  input_cost_per_token: 2.e-7
  output_cost_per_token: 2.e-7
limits:
  max_input_tokens: 131072
  max_output_tokens: 131072
capabilities:
  supports_chat: true
  supports_text: false
  supports_image: false
  supports_code: false
  supports_tools: false
  supports_pdf: false
  supports_doc: false
  supports_cache_control: false
params:
  - key: max_tokens
    maxValue: 4096
removeParams: []
requiredParams: []
mode: chat
defaultRegion: ''
deprecation_date: ''
is_deprecated: true
original_provider: perplexity
