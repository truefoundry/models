model: llama-2-70b-chat
costs:
  input_cost_per_token: 7.e-7
  output_cost_per_token: 0.0000028
limits:
  max_input_tokens: 4096
  max_output_tokens: 4096
features: [chat]
params:
  - key: max_tokens
    maxValue: 8192
removeParams: []
requiredParams: []
mode: chat
defaultRegion: ''
deprecation_date: ''
is_deprecated: true
original_provider: perplexity
