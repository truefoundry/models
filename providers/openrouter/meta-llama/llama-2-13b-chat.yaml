model: meta-llama/llama-2-13b-chat
costs:
  input_cost_per_token: 2.e-7
  output_cost_per_token: 2.e-7
limits:
  max_tokens: 4096
mode: chat
original_provider: openrouter
