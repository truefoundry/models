model: z-ai/glm-4.7-flash
costs:
  input_cost_per_token: 7.e-8
  output_cost_per_token: 4.e-7
  cache_read_input_token_cost: 0
  cache_creation_input_token_cost: 0
limits:
  max_tokens: 32000
  max_input_tokens: 200000
  max_output_tokens: 32000
features: [function_calling, vision]
mode: chat
original_provider: openrouter
