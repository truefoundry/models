model: z-ai/glm-4.7
costs:
  input_cost_per_token: 4.e-7
  output_cost_per_token: 0.0000015
  cache_read_input_token_cost: 0
  cache_creation_input_token_cost: 0
limits:
  max_tokens: 64000
  max_input_tokens: 202752
  max_output_tokens: 64000
features: [function_calling, vision]
mode: chat
original_provider: openrouter
