model: Meta-Llama-3.2-1B-Instruct
costs:
  input_cost_per_token: 4.e-8
  output_cost_per_token: 8.e-8
limits:
  max_tokens: 16384
  max_input_tokens: 16384
  max_output_tokens: 16384
features: []
source: https://cloud.sambanova.ai/plans/pricing
params: []
removeParams: []
requiredParams: []
mode: chat
defaultRegion: ''
deprecation_date: ''
is_deprecated: true
original_provider: sambanova
