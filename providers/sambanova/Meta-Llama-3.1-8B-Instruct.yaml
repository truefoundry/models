model: Meta-Llama-3.1-8B-Instruct
costs:
  input_cost_per_token: 1.e-7
  output_cost_per_token: 2.e-7
limits:
  max_tokens: 16384
  max_input_tokens: 16384
  max_output_tokens: 16384
capabilities:
  supports_function_calling: true
  supports_tool_choice: true
  supports_response_schema: true
source: https://cloud.sambanova.ai/plans/pricing
params: []
removeParams: []
requiredParams: []
mode: chat
defaultRegion: ''
deprecation_date: ''
is_deprecated: false
original_provider: sambanova
